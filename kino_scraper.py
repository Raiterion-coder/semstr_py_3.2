import json
import requests
from bs4 import BeautifulSoup


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–∞ —Å–∞–π—Ç–µ film.ru
def get_top_films(year: int, top_n: int = 5) -> str:
    url = f"https://www.film.ru/a-z/movies/{year}"
    headers = {"User-Agent": "Mozilla/5.0"}

    try:
        response = requests.get(url, headers=headers)  # –ü–æ–ª—É—á–µ–Ω–∏–µ html –∫–æ–¥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        response.raise_for_status()
    except requests.RequestException:
        return "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å —Å–∞–π—Ç–∞."

    soup = BeautifulSoup(response.text, "html.parser")
    script_tags = soup.find_all("script", type="application/ld+json")  # –ü–æ–∏—Å–∫ —Ç–µ–≥–æ–≤ –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç json-–¥–∞–Ω–Ω—ã–µ
    for script in script_tags:
        if "ItemList" in script.text and f"{year}" in script.text:  # –ü–æ–∏—Å–∫ <script>, –≤ –∫–æ—Ç–æ—Ä–æ–º –µ—Å—Ç—å —Å–ø–∏—Å–æ–∫ —Ñ–∏–ª—å–º–æ–≤ –ø–æ –∫–ª—é—á—É "ItemList" –∏ –≥–æ–¥—É
            try:
                data = json.loads(script.string)  # –ü—Ä–µ–≤—Ä–∞—â–µ–Ω–∏–µ –≤ —Å–ª–æ–≤–∞—Ä—å
                films = data.get("itemListElement", [])[:top_n]  # –ü–æ–∏—Å–∫ –∫–ª—é—á–∞ –∏ —Å—Ä–µ–∑ –¥–∞–Ω–Ω—ã—Ö
                if not films:
                    return "‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∏–ª—å–º–æ–≤."

                # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–≤–æ–¥–∞
                result = f"*–¢–æ–ø-{top_n} —Ñ–∏–ª—å–º–æ–≤ {year} –≥–æ–¥–∞:*\n"
                for item in films:
                    movie = item["item"]
                    title = movie.get("name")
                    url = movie.get("url")
                    result += f"üé¨ [{title}]({url})\n"
                return result
            except json.JSONDecodeError:
                continue

    return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ñ–∏–ª—å–º—ã –∑–∞ —ç—Ç–æ—Ç –≥–æ–¥."


def scrape_kinopoisk(title):
    search_url = f"https://www.kinopoisk.ru/index.php?kp_query={title}"
    headers = {"User-Agent": "Mozilla/5.0"}

    try:
        response = requests.get(search_url, headers=headers)  # –ü–æ–ª—É—á–µ–Ω–∏–µ html –∫–æ–¥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã

        soup = BeautifulSoup(response.content, "html.parser")
        first_result = soup.select_one(".search_results .element.most_wanted")  # –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º

        if not first_result:
            return "–§–∏–ª—å–º –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ –ö–∏–Ω–æ–ø–æ–∏—Å–∫–µ."
        name_tag = first_result.select_one("p.name a")  # –ü–æ–∏—Å–∫ –ø–æ CSS-—Å–µ–ª–µ–∫—Ç–æ—Ä—É
        name = name_tag.text.strip()
        link = "https://www.kinopoisk.ru" + name_tag["href"]

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∞ –∏–∑ div class="rating ratingGreenBG"
        rating_tag = first_result.select_one("div.rating.ratingGreenBG")
        rating = rating_tag.text.strip() if rating_tag else "–ù–µ—Ç —Ä–µ–π—Ç–∏–Ω–≥–∞"

        return f"üé¨ {name}\n‚≠ê –†–µ–π—Ç–∏–Ω–≥: {rating}\nüîó {link}"

    except Exception as e:
        return f"–û—à–∏–±–∫–∞ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞: {str(e)}"
